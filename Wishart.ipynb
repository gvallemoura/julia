{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teste para EIS Wishart em Julia.\n",
    "\n",
    "Modelos baseados no projeto CNPq.\n",
    "\n",
    "Teste trivariado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Densidade de observáveis:\n",
    "$$p(y_t|\\Sigma_t)\\sim N(0,\\Sigma_t)$$\n",
    "\n",
    "Densidade de transição dos estados:\n",
    "\n",
    "$$p(\\Sigma_t^{-1}|\\Sigma_{t-1}^{-1},v,d,C)\\sim W(v,S_{t-1})$$\n",
    "\n",
    "sendo que:\n",
    "\n",
    "$$S_{t-1}=\\frac{1}{v}(C^{1/2})(\\Sigma_{t-1})^{d}(C^{1/2})^{\\prime}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Array{Float64,2}:\n",
       " 6.66667  0.0      0.0    \n",
       " 0.0      6.66667  0.0    \n",
       " 0.0      0.0      6.66667"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pacotes\n",
    "using Distributions\n",
    "using PDMats\n",
    "using PyPlot\n",
    "\n",
    "# Constantes\n",
    "const LOG2PI = 1.83787706640934533908193770912475883960723876953125;\n",
    "const LOG2   = 0.69314718055994528622676398299518041312694549560546875;\n",
    "const LOGPI  = 1.1447298858494001638774761886452324688434600830078125;\n",
    "\n",
    "# Parametrização\n",
    "const K  = 3\n",
    "const T  = 240\n",
    "const N  = 500\n",
    "const d  = 0.5\n",
    "const v  = 14\n",
    "const iv = 1/v\n",
    "const Arg     = v-K+1:v\n",
    "const df_p1   = v+1                     # degrees of freedom from Wishart EIS initial sampler. See eq (17)\n",
    "const inds    = find(tril!(ones(K,K)))\n",
    "const Nb      = length(inds)            # number of estimated parameters from the covariance matrix or from the \\Gamma matrix filled with (k^2+k)/2 auxiliary parameters\n",
    "const ind_    = find(eye(K))            # index from a diagonal KxK matrix\n",
    "const itmax   = 5;                      # maximum number of iterations;\n",
    "const tol     = 0.01;                   # EIS tolerance to stop iterations;\n",
    "const semente = 123456789\n",
    "const Vini    = eye(K)./0.15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×8 Array{Float64,2}:\n",
       " 0.5  14.0  7.6761  -1.0835  -3.189  6.601  -1.1202  5.5048"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invC = PDMat([0.0238 0.0057 0.0145; 0.0057 0.0239 0.0056; 0.0145 0.0056 0.0330])\n",
    "C    = inv(invC)\n",
    "V0   = Vini\n",
    "par  = [0.5000   14.0000    7.6761   -1.0835   -3.1890    6.6010   -1.1202    5.5048]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240×3 Array{Float64,2}:\n",
       " -0.885021    0.00196412  -0.678012\n",
       "  1.792      -0.407463     2.14042 \n",
       "  0.472394    0.556765    -1.49857 \n",
       " -0.0384967  -0.505739     0.221759\n",
       "  1.01197     0.602443     1.33512 \n",
       " -0.0215475  -1.1741       0.352574\n",
       " -1.12179     0.557364    -1.65632 \n",
       "  1.33181     2.07583      2.78358 \n",
       "  0.151719    0.328076     1.90633 \n",
       " -3.0598     -2.40975     -4.4827  \n",
       "  0.604914    1.51072      1.30826 \n",
       " -0.426768   -2.44504      0.856805\n",
       " -0.0649287   0.825995    -1.25525 \n",
       "  ⋮                                \n",
       "  1.24187     1.10862      0.76207 \n",
       "  1.6812     -0.383984     1.71112 \n",
       " -1.02625    -0.522054    -0.656608\n",
       " -3.31528     0.658987     1.05307 \n",
       " -0.455854    1.10838     -2.66947 \n",
       "  0.0418779   0.591068    -1.51447 \n",
       "  0.742213    2.64011     -1.39113 \n",
       "  6.14713     0.229653     3.12921 \n",
       " -0.476619   -0.0843958   -0.548609\n",
       "  1.60292     0.645093     1.76743 \n",
       " -1.36957     0.158419    -2.00862 \n",
       " -0.631276   -0.240438    -0.362757"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt = readdlm(\"data3.csv\",',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nearestSPD (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function nearestSPD(A::Symmetric{Float64,Array{Float64,2}})\n",
    "# nearestSPD - the nearest [in Frobenius norm()] Symmetric Positive Definite matrix to A\n",
    "# usage: Ahat = nearestSPD[A]\n",
    "#\n",
    "# From Higham: \"The nearest symmetric positive semidefinite matrix in the\n",
    "# Frobenius norm to an arbitrary real matrix A is shown to be [B + H]/2\n",
    "# where H is the symmetric polar factor of B=(A + A')/2.\"\n",
    "#\n",
    "# http://www.sciencedirect.com/science/article/pii/0024379588902236\n",
    "#\n",
    "# arguments: (input())\n",
    "#  A - square matrix, which will be converted to the nearest Symmetric\n",
    "#    Positive Definite Matrix.\n",
    "#\n",
    "# Arguments: (output)\n",
    "#  Ahat - The matrix chosen as the nearest SPD matrix to A.\n",
    "\n",
    "\n",
    "# symmetrize A into B\n",
    "B = convert(Array,A)\n",
    "\n",
    "# Compute the symmetric polar factor of B. Call it H.\n",
    "# Clearly H is itself SPD.\n",
    "U,Sigma,V = svd(B)\n",
    "H = V*diagm(Sigma)*V'\n",
    "\n",
    "# get Ahat in the above formula\n",
    "Ahat = Symmetric((B+H)/2)\n",
    "\n",
    "# ensure symmetry\n",
    "# Ahat = (Ahat + Ahat')/2\n",
    "\n",
    "# test that Ahat is in fact PD. if it is not so, then tweak it just a bit.\n",
    "k = 0\n",
    "p = 1\n",
    "while p>0\n",
    "    k = k+1\n",
    "    try\n",
    "        Ahat = PDMat(Ahat)\n",
    "        p = -1\n",
    "    catch\n",
    "        # Ahat failed the chol test. It must have been just a hair off\n",
    "        # due to floating point trash, so it is simplest now just to\n",
    "        # tweak by adding a tiny multiple of an identity matrix.\n",
    "        valor,Vec = eig(Ahat)\n",
    "        mineig = minimum(valor)\n",
    "        Ahat = Ahat + (-mineig*k.^2 + eps(mineig))*eye(size(A,1))\n",
    "    end\n",
    "end\n",
    "return Ahat\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PDMats.PDMat{Float64,Array{Float64,2}}(3, [58.9225 -8.31705 -24.4791; -8.31705 44.7472 -3.93916; -24.4791 -3.93916 41.7274], Base.LinAlg.Cholesky{Float64,Array{Float64,2}} with factor:\n",
       "[7.6761 -1.0835 -3.189; 0.0 6.601 -1.1202; 0.0 0.0 5.5048])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters and variables for EIS iterations\n",
    "Neis    = 100\n",
    "it      = 0\n",
    "diff    = 100                         # initial difference;\n",
    "bet     = zeros(Nb+1,T)              # initialize vector to save EIS parameters;\n",
    "betas_0 = bet                         # initialize EIS parameters at zero for initial sampler. See paragraph bellow eq. (17);\n",
    "VINI    = Array{Float64,3}(K,K,Neis)\n",
    "for i=1:Neis\n",
    "    VINI[:,:,i]    = Vini             # state at t=0. Initial condition is treated as given\n",
    "end\n",
    "Y       = Array{Float64,2}(Neis,T-1)    # dependent variable for EIS regression;\n",
    "XX      = Array{Float64,3}(Neis,Nb+1,T) # set space for Neis draws of EIS parameters at each period t;\n",
    "Ytm1    = Array{Float64,2}(Neis,1)      # set space for Neis evaluations of the EIS objective function.\n",
    "indd    = Array{Int64,1}(K+1)\n",
    "for i=1:K\n",
    "    hu      = find(inds.==ind_[i])\n",
    "    indd[i] = hu[1]                    # indicate the linear indice in \"inds\" which corresponds to a diagonal parameter;\n",
    "end\n",
    "indd[end] = Nb+1\n",
    "cC        = zeros(K,K)\n",
    "cC[inds]  = par[3:Nb+2]                # maps parameters to cC matrix in order to recriate matrix cC;\n",
    "cC        = reshape(cC,K,K)            # reorganize matrix;\n",
    "C         = PDMat(cC*cC')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Array{Float64,2}:\n",
       "  7.6761   0.0     0.0   \n",
       " -1.0835   6.601   0.0   \n",
       " -3.189   -1.1202  5.5048"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# while it<itmax\n",
    "t,i = 1,1\n",
    "    # Use CRNs\n",
    "    srand(semente)\n",
    "    # Initialize EIS sampler. See eq.(17):\n",
    "    V0        = Vini                     # initial state is given in this exercise;\n",
    "    df_eis    = bet[end,:].+df_p1\n",
    "    df_eis    = [df_eis; df_p1]          # degrees of freedom of EIS samplers from t=1 to t=T. Note that for t=T, df_eis=df_p1, since filter estimate is equal to smoothed estimate at T;\n",
    "#     for t=1:T\n",
    "        BetMat       = zeros(K,K)        # BetMat will be used as the \\Gamma matrix from Eq. (17), which collects (k^2+k)/2 auxiliary parameters from the scale matrix of the EIS sampler\n",
    "        BetMat[inds] = bet[1:Nb,t]\n",
    "        BetMat       = BetMat+tril(BetMat,-1)'\n",
    "        EISmat       = BetMat+yt[t,:]*yt[t,:]'\n",
    "        df_eis_t     = df_eis[t];\n",
    "#         if t==1\n",
    "            cVd = V0.^(d/2)\n",
    "            Veist = Array{Float64,3}(K,K,Neis)\n",
    "            XXX   = Array{Float64,2}(Neis,Nb+1)\n",
    "            sS  = C.chol[:L]*cVd*sqrt(iv)\n",
    "            # Compute symmetric PDMatrix scale matrix\n",
    "            S   = (sS*sS')\n",
    "            EISmatS = EISmat*(sS*sS')\n",
    "            Seis = PDMat(Symmetric(S-1/(1+trace(EISmatS))*S*EISmatS))\n",
    "#             for  i=1:Neis\n",
    "#                 Veist[:,:,i] = rand(Wishart(df_eis_t,Seis))\n",
    "#                 XX[i,1,t] = Veist[1,1,i]*0.5\n",
    "#                 XX[i,2,t] = Veist[2,1,i]\n",
    "#                 XX[i,3,t] = Veist[3,1,i]\n",
    "#                 XX[i,4,t] = Veist[2,2,i]*0.5\n",
    "#                 XX[i,5,t] = Veist[3,2,i]\n",
    "#                 XX[i,6,t] = Veist[3,3,i]*0.5\n",
    "#                 XX[i,7,t] = logdet(Veist[:,:,i])*0.5\n",
    "#             end\n",
    "#             V0 = Veist\n",
    "#         else\n",
    "#             Veist = Array{Float64,3}(K,K,Neis)\n",
    "#             XXX   = Array{Float64,2}(Neis,Nb+1)\n",
    "#             for i=1:Neis\n",
    "#                 # Compute Eigenvalue decomposition\n",
    "#                 value,V = eig(V0[:,:,i])\n",
    "#                 sS  = C.chol[:L]*V*diagm(value.^(d/2))*sqrt(iv)\n",
    "#                 # Compute symmetric PDMatrix scale matrix\n",
    "#                 S   = (sS*sS')\n",
    "#                 EISmatS = EISmat*S\n",
    "#                 Seis = PDMat(Symmetric(S-1/(1+trace(EISmatS))*S*EISmatS))\n",
    "#                 # Compute integrating constant \\Chi_{t} for smoothing. See Eq. (18).\n",
    "#                 logdetStm1 = logdet(Seis)\n",
    "#                 logdetS    = logdet(PDMat(S));\n",
    "#                 Ytm1[i]    = 0.5*(df_eis_t*logdetStm1-v*logdetS); # log of integrating constant, which is a scalar;\n",
    "#                 Veist[:,:,i] = rand(Wishart(df_eis_t,Seis))\n",
    "#                 XX[i,1,t] = Veist[1,1,i]*0.5\n",
    "#                 XX[i,2,t] = Veist[2,1,i]\n",
    "#                 XX[i,3,t] = Veist[3,1,i]\n",
    "#                 XX[i,4,t] = Veist[2,2,i]*0.5\n",
    "#                 XX[i,5,t] = Veist[3,2,i]\n",
    "#                 XX[i,6,t] = Veist[3,3,i]*0.5\n",
    "#                 XX[i,7,t] = logdet(Veist[:,:,i])*0.5\n",
    "#             end\n",
    "#             Y[:,t-1] = Ytm1;\n",
    "#             if t<T\n",
    "#                 V0 = Veist\n",
    "#             end\n",
    "#         end\n",
    "#     end\n",
    "#     # Backward EIS loop to smooth EIS estimates of t (\\Chi_{t}) with integrating constant of t+1 (\\Chi_{t+1})\n",
    "#     for t = T-1:-1:1\n",
    "#         X = [ones(Neis,1) XX[:,:,t]]  # EIS regressors. Obs: X uses the sample of N draws to estime EIS parameters, collected by beta;\n",
    "#         b = (X'*X)\\(X'*Y[:,t])     # EIS parameters. Beta is a Nb+2 x 1 matrix;\n",
    "#         bet[:,t] = b[2:end]        # Save EIS parameters eliminating those w.r.t. the constant. Matrix bet(:,t) becomes Nb+1 x 1 again;\n",
    "#     end\n",
    "#     # Check convergence:\n",
    "#     diff = sum(sum(abs.(bet[1:end-1,:]-betas_0[1:end-1,:]))) # compute sum of individual relative difference between beta_{t} and beta_{t-1}. Obs: it is also possible to compute percentage change in parameters;\n",
    "#     #println(diff)\n",
    "#     betas_0 = copy(bet)\n",
    "#     # Count EIS iterations\n",
    "#     it = it+1\n",
    "# end\n",
    "# # Sample from optimized EIS sampler:\n",
    "# V0   = Array{Float64,3}(K,K,N)\n",
    "# for i=1:N\n",
    "#     V0[:,:,i] = Vini              # state at t=0. Initial condition is treated as given\n",
    "# end\n",
    "# Veist  = Array{Float64,3}(K,K,N);\n",
    "# df_eis = bet[end,:].+df_p1\n",
    "# df_eis = [df_eis; df_p1]          # degrees of freedom of EIS samplers from t=1 to t=T. Note that for t=T, df_eis=df_p1, since filter estimate is equal to smoothed estimate at T;\n",
    "# srand(semente*3)                  # use different seed after optimization\n",
    "\n",
    "# # Evaluate EIS Integrand for MC integration using draws from optimized EIS sampler.\n",
    "# ratio = Array{Float64,2}(T,N);\n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "DomainError:\nExponentiation yielding a complex result requires a complex argument.\nReplace x^y with (x+0im)^y, Complex(x)^y, or similar.",
     "output_type": "error",
     "traceback": [
      "DomainError:\nExponentiation yielding a complex result requires a complex argument.\nReplace x^y with (x+0im)^y, Complex(x)^y, or similar.",
      "",
      "Stacktrace:",
      " [1] \u001b[1mnan_dom_err\u001b[22m\u001b[22m at \u001b[1m./math.jl:300\u001b[22m\u001b[22m [inlined]",
      " [2] \u001b[1m^\u001b[22m\u001b[22m at \u001b[1m./math.jl:699\u001b[22m\u001b[22m [inlined]",
      " [3] \u001b[1mmacro expansion\u001b[22m\u001b[22m at \u001b[1m./broadcast.jl:155\u001b[22m\u001b[22m [inlined]",
      " [4] \u001b[1mmacro expansion\u001b[22m\u001b[22m at \u001b[1m./simdloop.jl:73\u001b[22m\u001b[22m [inlined]",
      " [5] \u001b[1mmacro expansion\u001b[22m\u001b[22m at \u001b[1m./broadcast.jl:149\u001b[22m\u001b[22m [inlined]",
      " [6] \u001b[1m_broadcast!\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Base.#^, ::Array{Float64,1}, ::Tuple{Tuple{Bool},Tuple{}}, ::Tuple{Tuple{Int64},Tuple{}}, ::Array{Float64,1}, ::Tuple{Float64}, ::Type{Val{1}}, ::CartesianRange{CartesianIndex{1}}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./broadcast.jl:141\u001b[22m\u001b[22m",
      " [7] \u001b[1mbroadcast_t\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Function, ::Type{T} where T, ::Tuple{Base.OneTo{Int64}}, ::CartesianRange{CartesianIndex{1}}, ::Array{Float64,1}, ::Float64\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./broadcast.jl:270\u001b[22m\u001b[22m",
      " [8] \u001b[1mbroadcast_c\u001b[22m\u001b[22m at \u001b[1m./broadcast.jl:316\u001b[22m\u001b[22m [inlined]",
      " [9] \u001b[1mbroadcast\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Function, ::Array{Float64,1}, ::Float64\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./broadcast.jl:455\u001b[22m\u001b[22m",
      " [10] \u001b[1mmacro expansion\u001b[22m\u001b[22m at \u001b[1m./In[8]:12\u001b[22m\u001b[22m [inlined]",
      " [11] \u001b[1manonymous\u001b[22m\u001b[22m at \u001b[1m./<missing>:?\u001b[22m\u001b[22m",
      " [12] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:522\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": [
    "for t=1:T\n",
    "#    ytt          = yt[t,:]\n",
    "    BetMat       = zeros(K,K)              # BetMat will be used as the \\Gamma matrix from Eq. (17), which collects (k^2+k)/2 auxiliary parameters from the scale matrix of the EIS sampler\n",
    "    BetMat[inds] = bet[1:Nb,t]\n",
    "    BetMat       = BetMat+tril(BetMat,-1)'\n",
    "    EISmat       = BetMat+yt[t,:]*yt[t,:]'\n",
    "    df_eis_t     = df_eis[t];\n",
    "    ArgEIS       = (df_eis_t-K+1:df_eis_t)\n",
    "    for i=1:N\n",
    "        # Compute Eigenvalue decomposition\n",
    "        value,V = eig(V0[:,:,i])\n",
    "        sS  = C.chol[:L]*V*diagm(value.^(d/2))*sqrt(iv)\n",
    "        # Compute symmetric PDMatrix scale matrix\n",
    "        S   = (sS*sS')\n",
    "        Ss  = PDMat(S)\n",
    "        EISmatS = (Ss*EISmat)'\n",
    "        Seis = Symmetric(S-1/(1+trace(EISmatS))*S*EISmatS)\n",
    "        if isposdef(Seis)\n",
    "            Seis = PDMat(Seis)\n",
    "        else\n",
    "            Seis = nearestSPD(Seis)\n",
    "        end\n",
    "        Veist[:,:,i] = rand(Wishart(df_eis_t,Seis))\n",
    "        Veisti = PDMat(Veist[:,:,i])\n",
    "        logdetVeis   = logdet(Veisti)\n",
    "        # Measurement density in logs\n",
    "        lgt = -K/2*LOG2PI+0.5*logdetVeis-0.5*quad(Veisti,yt[t,:])#yt[t,:]'*Veist[:,:,i]*yt[t,:]\n",
    "        # State Transition Density in logs\n",
    "        cnstt  = logdet(Ss)*(-v/2)-(v*K*.5)*LOG2-((K*(K-1))/4)*LOGPI-sum(lgamma.(Arg/2))\n",
    "        kernel = logdetVeis*((v-K-1)/2) -.5*sum(diag(Ss\\Veist[:,:,i]))\n",
    "        lpt =  cnstt+kernel\n",
    "        # Importance Sampler in logs\n",
    "        cnstt  = logdet(Seis)*(-df_eis_t/2)-(df_eis_t*K*.5)*LOG2-((K*(K-1))/4)*LOGPI-sum(lgamma.(ArgEIS/2))\n",
    "        kernel = logdetVeis*((df_eis_t-K-1)/2) -.5*sum(diag(Seis\\Veist[:,:,i]))\n",
    "        lmt    = cnstt+kernel\n",
    "        # IS ratio\n",
    "        ratio[t,i] = (lgt+lpt-lmt)\n",
    "    end\n",
    "    if t<T\n",
    "        V0 = Veist\n",
    "    end\n",
    "end\n",
    "\n",
    "# lik = mean(exp.(sum(ratio.-adj,1)))    # adjust ratio against overflows due to exponentiation;\n",
    "# loglik = log(lik)+T*adj                # loglikelihood;\n",
    "# n_loglik = -loglik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Symmetric{Float64,Array{Float64,2}}:\n",
       " -0.145912   0.0170917   -0.114009 \n",
       "  0.0170917  0.00982586   0.0392737\n",
       " -0.114009   0.0392737   -0.100044 "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BetMat       = zeros(K,K)              # BetMat will be used as the \\Gamma matrix from Eq. (17), which collects (k^2+k)/2 auxiliary parameters from the scale matrix of the EIS sampler\n",
    "    BetMat[inds] = bet[1:Nb,t]\n",
    "    BetMat       = Symmetric(BetMat,:L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000005 seconds (5 allocations: 192 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3×3 Symmetric{Float64,Array{Float64,2}}:\n",
       " -0.145912   0.0170917   -0.114009 \n",
       "  0.0170917  0.00982586   0.0392737\n",
       " -0.114009   0.0392737   -0.100044 "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BetMat1       = rand(Wishart(1000,eye(3)))              # BetMat will be used as the \\Gamma matrix from Eq. (17), which collects (k^2+k)/2 auxiliary parameters from the scale matrix of the EIS sampler\n",
    "    BetMat1[inds] = bet[1:Nb,t]\n",
    "@time    BetMat1       = Symmetric(BetMat1,:L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Symmetric{Float64,Array{Float64,2}}:\n",
       " -0.145912   0.0170917   -0.114009 \n",
       "  0.0170917  0.00982586   0.0392737\n",
       " -0.114009   0.0392737   -0.100044 "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sample from optimized EIS sampler:\n",
    "V0   = Array{Float64,3}(K,K,N)\n",
    "for i=1:N\n",
    "    V0[:,:,i] = Vini              # state at t=0. Initial condition is treated as given\n",
    "end\n",
    "Veist  = Array{Float64,3}(K,K,N);\n",
    "df_eis = bet[end,:].+df_p1 \n",
    "df_eis = [df_eis; df_p1]          # degrees of freedom of EIS samplers from t=1 to t=T. Note that for t=T, df_eis=df_p1, since filter estimate is equal to smoothed estimate at T;\n",
    "srand(semente*3)                  # use different seed after optimization\n",
    "\n",
    "# Evaluate EIS Integrand for MC integration using draws from optimized EIS sampler.\n",
    "ratio = Array{Float64,2}(T,N);\n",
    "\n",
    "# Construct moments of EIS optimized sampler\n",
    "for t=1:T\n",
    "#    ytt          = yt[t,:]\n",
    "    BetMat       = zeros(K,K)              # BetMat will be used as the \\Gamma matrix from Eq. (17), which collects (k^2+k)/2 auxiliary parameters from the scale matrix of the EIS sampler\n",
    "    BetMat[inds] = bet[1:Nb,t]\n",
    "    BetMat       = BetMat+tril(BetMat,-1)'\n",
    "    EISmat       = BetMat+yt[t,:]*yt[t,:]'\n",
    "    df_eis_t     = df_eis[t];\n",
    "    for i=1:N\n",
    "        # Compute Eigenvalue decomposition\n",
    "        value,V = eig(V0[:,:,i])\n",
    "        cV0 = V*diagm(value).^(d/2)\n",
    "        sS  = C.chol[:L]*cV0*(iv/2) \n",
    "        # Compute symmetric PDMatrix scale matrix\n",
    "        S   = (sS*sS') \n",
    "#         Ss  = PDMat(S)\n",
    "        EISmatS = EISmat*S\n",
    "        Seis = PDMat(Symmetric(S-1/(1+trace(EISmatS))*S*EISmatS))\n",
    "        Veist[:,:,i] = rand(Wishart(df_eis_t,Seis))\n",
    "        Veisti = PDMat(Veist[:,:,i])\n",
    "        logdetVeis   = logdet(Veisti)\n",
    "        # Measurement density in logs\n",
    "        lgt = -K/2*LOG2PI+0.5*logdetVeis-0.5*quad(Veisti,yt[t,:])#yt[t,:]'*Veist[:,:,i]*yt[t,:]\n",
    "        # State Transition Density in logs\n",
    "        cnstt  = logdet(S)*(-v/2)-(v*K*.5)*LOG2-((K*(K-1))/4)*LOGPI-sum(lgamma.(Arg/2))\n",
    "        kernel = logdetVeis*((v-K-1)/2) -.5*sum(diag(S\\Veist[:,:,i]))\n",
    "        lpt =  cnstt+kernel\n",
    "        # Importance Sampler in logs\n",
    "        ArgEIS = (df_eis_t-K+1:df_eis_t)\n",
    "        cnstt  = logdet(Seis)*(-df_eis_t/2)-(df_eis_t*K*.5)*LOG2-((K*(K-1))/4)*LOGPI-sum(lgamma.(ArgEIS/2))\n",
    "        kernel = logdetVeis*((df_eis_t-K-1)/2) -.5*sum(diag(Seis\\Veist[:,:,i]))\n",
    "        lmt    = cnstt+kernel\n",
    "        # IS ratio\n",
    "        ratio[t,i] = (lgt+lpt-lmt) \n",
    "    end\n",
    "    if t<T\n",
    "        V0 = Veist\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adj = -5.9\n",
    "lik = mean(exp.(sum(ratio.-adj,1)))    # adjust ratio against overflows due to exponentiation;\n",
    "loglik = log(lik)+T*adj                # loglikelihood;\n",
    "n_loglik = -loglik      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hu=Veist[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
